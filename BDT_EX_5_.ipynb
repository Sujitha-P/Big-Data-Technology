{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4e1012UVu5V",
        "outputId": "d5985c6d-809b-4035-9638-2e471dc4b265"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-14 17:32:51--  https://downloads.apache.org/pig/pig-0.17.0/pig-0.17.0.tar.gz\n",
            "Resolving downloads.apache.org (downloads.apache.org)... 135.181.214.104, 88.99.208.237, 2a01:4f8:10a:39da::2, ...\n",
            "Connecting to downloads.apache.org (downloads.apache.org)|135.181.214.104|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 230606579 (220M) [application/x-gzip]\n",
            "Saving to: ‘pig-0.17.0.tar.gz.2’\n",
            "\n",
            "pig-0.17.0.tar.gz.2 100%[===================>] 219.92M  79.9MB/s    in 2.8s    \n",
            "\n",
            "2025-11-14 17:32:54 (79.9 MB/s) - ‘pig-0.17.0.tar.gz.2’ saved [230606579/230606579]\n",
            "\n",
            "mv: cannot move 'pig-0.17.0' to '/content/pig/pig-0.17.0': Directory not empty\n"
          ]
        }
      ],
      "source": [
        "!wget https://downloads.apache.org/pig/pig-0.17.0/pig-0.17.0.tar.gz\n",
        "!tar -xzf pig-0.17.0.tar.gz\n",
        "!mv pig-0.17.0 /content/pig\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "students = \"\"\"1,Reena,CSE,85\n",
        "2,Anita,IT,55\n",
        "3,James,CSE,72\n",
        "4,Kiran,ECE,67\n",
        "5,Manish,IT,90\n",
        "\"\"\"\n",
        "with open(\"students.csv\", \"w\") as f:\n",
        "    f.write(students)\n",
        "\n",
        "departments = \"\"\"ECE,Dr.Sharma\n",
        "IT,Dr.Vaavar\n",
        "CSE,Dr.Rao\n",
        "\"\"\"\n",
        "with open(\"departments.csv\", \"w\") as f:\n",
        "    f.write(departments)\n"
      ],
      "metadata": {
        "id": "3MQtqIlfafsZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pig_script = \"\"\"\n",
        "students = LOAD 'students.csv' USING PigStorage(',')\n",
        "           AS (id:int, name:chararray, dept:chararray, marks:int);\n",
        "\n",
        "departments = LOAD 'departments.csv' USING PigStorage(',')\n",
        "              AS (dept:chararray, hod:chararray);\n",
        "\n",
        "good_students = FILTER students BY marks > 60;\n",
        "\n",
        "projected = FOREACH good_students GENERATE name, dept, marks;\n",
        "\n",
        "grouped = GROUP projected BY dept;\n",
        "\n",
        "sorted = ORDER projected BY marks DESC;\n",
        "\n",
        "joined = JOIN projected BY dept, departments BY dept;\n",
        "\n",
        "DUMP sorted;\n",
        "DUMP grouped;\n",
        "DUMP joined;\n",
        "\"\"\"\n",
        "\n",
        "with open(\"program.pig\", \"w\") as f:\n",
        "    f.write(pig_script)\n",
        "\n",
        "print(\"Pig Script Saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eb2llKp8ajZ6",
        "outputId": "434421fd-ecf9-4a8c-b151-9864b8a75017"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pig Script Saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update -y\n",
        "!apt-get install openjdk-11-jdk -y\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vUjuR15ayFD",
        "outputId": "c5fd7909-ae69-453b-d391-1d9159747502"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.82)] [Connected to cloud.r-pr\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [Connected to cloud.r-project.org (65.9.86.28)] [Conne\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "\r0% [Waiting for headers] [Connected to cloud.r-project.org (65.9.86.28)] [Conne\r                                                                               \rHit:4 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "\r0% [Connected to cloud.r-project.org (65.9.86.28)] [Connecting to r2u.stat.illi\r                                                                               \rHit:5 https://cli.github.com/packages stable InRelease\n",
            "\r0% [Connected to cloud.r-project.org (65.9.86.28)] [Connecting to r2u.stat.illi\r                                                                               \rHit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\r0% [Waiting for headers] [Connecting to r2u.stat.illinois.edu (192.17.190.167)]\r                                                                               \rHit:7 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\r0% [Connecting to r2u.stat.illinois.edu (192.17.190.167)] [Waiting for headers]\r                                                                               \rHit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "\r                                                                               \r0% [Connected to r2u.stat.illinois.edu (192.17.190.167)] [Waiting for headers]\r                                                                              \rHit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "openjdk-11-jdk is already the newest version (11.0.28+6-1ubuntu1~22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 46 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /usr/lib/jvm/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TU8sByI-a92D",
        "outputId": "7615e3e8-e6e9-4f55-b20b-c43d510a5f0b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "java-1.11.0-openjdk-amd64  java-11-openjdk-amd64  openjdk-11\n",
            "java-1.17.0-openjdk-amd64  java-17-openjdk-amd64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "os.environ[\"PIG_HOME\"] = \"/content/pig\"\n",
        "os.environ[\"PATH\"] += \":/content/pig/bin\"\n"
      ],
      "metadata": {
        "id": "7O6bO5DfbDuv"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pig -x local program.pig\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edalpuY2anVe",
        "outputId": "30f576d3-9a0b-41d5-b828-971ca52bc2e9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: An illegal reflective access operation has occurred\n",
            "WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/content/pig/lib/hadoop2-runtime/hadoop-auth-2.7.3.jar) to method sun.security.krb5.Config.getInstance()\n",
            "WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil\n",
            "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
            "WARNING: All illegal access operations will be denied in a future release\n",
            "2025-11-14 17:33:20,181 INFO  [main] pig.ExecTypeProvider (ExecTypeProvider.java:selectExecType(41)) - Trying ExecType : LOCAL\n",
            "2025-11-14 17:33:20,183 INFO  [main] pig.ExecTypeProvider (ExecTypeProvider.java:selectExecType(43)) - Picked LOCAL as the ExecType\n",
            "2025-11-14 17:33:20,253 [main] INFO  org.apache.pig.Main - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58\n",
            "2025-11-14 17:33:20,255 [main] INFO  org.apache.pig.Main - Logging error messages to: /content/pig_1763141600242.log\n",
            "2025-11-14 17:33:20,281 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - user.name is deprecated. Instead, use mapreduce.job.user.name\n",
            "2025-11-14 17:33:20,676 [main] INFO  org.apache.pig.impl.util.Utils - Default bootup file /root/.pigbootup not found\n",
            "2025-11-14 17:33:20,880 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
            "2025-11-14 17:33:20,882 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine - Connecting to hadoop file system at: file:///\n",
            "2025-11-14 17:33:20,911 [main] INFO  org.apache.pig.PigServer - Pig Script ID for the session: PIG-program.pig-b662ffab-a2de-4409-adce-5ea63ef408a3\n",
            "2025-11-14 17:33:20,911 [main] WARN  org.apache.pig.PigServer - ATS is disabled since yarn.timeline-service.enabled set to false\n",
            "2025-11-14 17:33:21,512 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
            "2025-11-14 17:33:21,566 [main] INFO  org.apache.pig.tools.pigstats.ScriptState - Pig features used in the script: ORDER_BY,FILTER\n",
            "2025-11-14 17:33:21,635 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}\n",
            "2025-11-14 17:33:21,662 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor - Columns pruned for students: $0\n",
            "2025-11-14 17:33:21,706 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (G1 Old Gen) of size 1048576000 to monitor. collectionUsageThreshold = 734003200, usageThreshold = 734003200\n",
            "2025-11-14 17:33:21,761 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler - File concatenation threshold: 100 optimistic? false\n",
            "2025-11-14 17:33:21,797 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR - Using Secondary Key Optimization for MapReduce node scope-28\n",
            "2025-11-14 17:33:21,804 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - MR plan size before optimization: 3\n",
            "2025-11-14 17:33:21,805 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - MR plan size after optimization: 3\n",
            "2025-11-14 17:33:21,903 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id\n",
            "2025-11-14 17:33:21,904 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=\n",
            "2025-11-14 17:33:21,980 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
            "2025-11-14 17:33:21,990 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
            "2025-11-14 17:33:21,990 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
            "2025-11-14 17:33:21,992 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress\n",
            "2025-11-14 17:33:22,018 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
            "2025-11-14 17:33:22,032 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Key [pig.schematuple] is false, will not generate code.\n",
            "2025-11-14 17:33:22,032 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Starting process to move generated code to distributed cacche\n",
            "2025-11-14 17:33:22,032 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Distributed cache not supported or needed in local mode. Setting key [pig.schematuple.local.dir] with code temp directory: /tmp/1763141602032-0\n",
            "2025-11-14 17:33:22,118 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
            "2025-11-14 17:33:22,120 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker.http.address is deprecated. Instead, use mapreduce.jobtracker.http.address\n",
            "2025-11-14 17:33:22,130 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
            "2025-11-14 17:33:22,167 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
            "2025-11-14 17:33:22,308 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
            "2025-11-14 17:33:22,319 [JobControl] INFO  org.apache.pig.builtin.PigStorage - Using PigTextInputFormat\n",
            "2025-11-14 17:33:22,324 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1\n",
            "2025-11-14 17:33:22,324 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
            "2025-11-14 17:33:22,342 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
            "2025-11-14 17:33:22,431 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
            "2025-11-14 17:33:22,981 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1292723063_0001\n",
            "2025-11-14 17:33:23,374 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
            "2025-11-14 17:33:23,382 [Thread-19] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
            "2025-11-14 17:33:23,441 [Thread-19] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
            "2025-11-14 17:33:23,445 [Thread-19] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
            "2025-11-14 17:33:23,451 [Thread-19] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
            "2025-11-14 17:33:23,455 [Thread-19] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
            "2025-11-14 17:33:23,559 [Thread-19] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
            "2025-11-14 17:33:23,564 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1292723063_0001_m_000000_0\n",
            "2025-11-14 17:33:23,691 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
            "2025-11-14 17:33:23,736 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
            "2025-11-14 17:33:23,757 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
            "Total Length = 74\n",
            "Input split[0]:\n",
            "   Length = 74\n",
            "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
            "   Locations:\n",
            "\n",
            "-----------------------\n",
            "\n",
            "2025-11-14 17:33:23,785 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.builtin.PigStorage - Using PigTextInputFormat\n",
            "2025-11-14 17:33:23,794 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/content/students.csv:0+74\n",
            "2025-11-14 17:33:23,817 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
            "2025-11-14 17:33:23,854 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (G1 Old Gen) of size 1048576000 to monitor. collectionUsageThreshold = 734003200, usageThreshold = 734003200\n",
            "2025-11-14 17:33:23,855 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.data.SchemaTupleBackend - Key [pig.schematuple] was not set... will not generate code.\n",
            "2025-11-14 17:33:23,877 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local1292723063_0001\n",
            "2025-11-14 17:33:23,878 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases good_students,projected,students\n",
            "2025-11-14 17:33:23,878 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: students[2,11],students[-1,-1],good_students[8,16],projected[10,12] C:  R: \n",
            "2025-11-14 17:33:23,883 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapOnly$Map - Aliases being processed per job phase (AliasName[line,offset]): M: students[2,11],students[-1,-1],good_students[8,16],projected[10,12] C:  R: \n",
            "2025-11-14 17:33:23,891 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
            "2025-11-14 17:33:23,892 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1292723063_0001_m_000000_0 is done. And is in the process of committing\n",
            "2025-11-14 17:33:23,899 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 0% complete\n",
            "2025-11-14 17:33:23,900 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_local1292723063_0001]\n",
            "2025-11-14 17:33:23,927 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
            "2025-11-14 17:33:23,927 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1292723063_0001_m_000000_0 is allowed to commit now\n",
            "2025-11-14 17:33:23,941 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1292723063_0001_m_000000_0' to file:/tmp/temp-669726848/tmp-946096885/_temporary/0/task_local1292723063_0001_m_000000\n",
            "2025-11-14 17:33:23,942 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
            "2025-11-14 17:33:23,942 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1292723063_0001_m_000000_0' done.\n",
            "2025-11-14 17:33:23,942 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1292723063_0001_m_000000_0\n",
            "2025-11-14 17:33:23,944 [Thread-19] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
            "2025-11-14 17:33:24,084 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 33% complete\n",
            "2025-11-14 17:33:24,094 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
            "2025-11-14 17:33:24,115 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
            "2025-11-14 17:33:24,118 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
            "2025-11-14 17:33:24,118 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
            "2025-11-14 17:33:24,122 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
            "2025-11-14 17:33:24,201 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
            "2025-11-14 17:33:24,202 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
            "2025-11-14 17:33:24,205 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
            "2025-11-14 17:33:24,208 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Using reducer estimator: org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator\n",
            "2025-11-14 17:33:24,210 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator - BytesPerReducer=1000000000 maxReducers=999 totalInputFileSize=80\n",
            "2025-11-14 17:33:24,213 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
            "2025-11-14 17:33:24,220 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
            "2025-11-14 17:33:24,287 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
            "2025-11-14 17:33:24,302 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
            "2025-11-14 17:33:24,333 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
            "2025-11-14 17:33:24,366 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1\n",
            "2025-11-14 17:33:24,366 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
            "2025-11-14 17:33:24,366 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
            "2025-11-14 17:33:24,445 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
            "2025-11-14 17:33:24,476 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local302270355_0002\n",
            "2025-11-14 17:33:24,724 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
            "2025-11-14 17:33:24,725 [Thread-44] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
            "2025-11-14 17:33:24,748 [Thread-44] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
            "2025-11-14 17:33:24,748 [Thread-44] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
            "2025-11-14 17:33:24,748 [Thread-44] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
            "2025-11-14 17:33:24,749 [Thread-44] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
            "2025-11-14 17:33:24,749 [Thread-44] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
            "2025-11-14 17:33:24,759 [Thread-44] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
            "2025-11-14 17:33:24,759 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local302270355_0002_m_000000_0\n",
            "2025-11-14 17:33:24,778 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
            "2025-11-14 17:33:24,779 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
            "2025-11-14 17:33:24,784 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
            "Total Length = 80\n",
            "Input split[0]:\n",
            "   Length = 80\n",
            "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
            "   Locations:\n",
            "\n",
            "-----------------------\n",
            "\n",
            "2025-11-14 17:33:24,789 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/tmp/temp-669726848/tmp-946096885/part-m-00000:0+80\n",
            "2025-11-14 17:33:24,796 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local302270355_0002\n",
            "2025-11-14 17:33:24,796 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases sorted\n",
            "2025-11-14 17:33:24,796 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: sorted[14,9] C:  R: \n",
            "2025-11-14 17:33:24,938 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2025-11-14 17:33:24,938 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
            "2025-11-14 17:33:24,938 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
            "2025-11-14 17:33:24,938 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
            "2025-11-14 17:33:24,938 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
            "2025-11-14 17:33:24,969 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2025-11-14 17:33:24,980 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (G1 Old Gen) of size 1048576000 to monitor. collectionUsageThreshold = 734003200, usageThreshold = 734003200\n",
            "2025-11-14 17:33:24,980 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
            "2025-11-14 17:33:24,987 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: sorted[14,9] C:  R: \n",
            "2025-11-14 17:33:25,004 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
            "2025-11-14 17:33:25,005 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
            "2025-11-14 17:33:25,005 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
            "2025-11-14 17:33:25,005 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 64; bufvoid = 104857600\n",
            "2025-11-14 17:33:25,005 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214384(104857536); length = 13/6553600\n",
            "2025-11-14 17:33:25,011 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
            "2025-11-14 17:33:25,017 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local302270355_0002_m_000000_0 is done. And is in the process of committing\n",
            "2025-11-14 17:33:25,020 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
            "2025-11-14 17:33:25,020 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local302270355_0002_m_000000_0' done.\n",
            "2025-11-14 17:33:25,020 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local302270355_0002_m_000000_0\n",
            "2025-11-14 17:33:25,021 [Thread-44] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
            "2025-11-14 17:33:25,024 [pool-5-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local302270355_0002_r_000000_0\n",
            "2025-11-14 17:33:25,025 [Thread-44] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
            "2025-11-14 17:33:25,040 [pool-5-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
            "2025-11-14 17:33:25,044 [pool-5-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
            "2025-11-14 17:33:25,047 [pool-5-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@162fb99d\n",
            "2025-11-14 17:33:25,063 [pool-5-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=734003200, maxSingleShuffleLimit=183500800, mergeThreshold=484442144, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
            "2025-11-14 17:33:25,068 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local302270355_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
            "2025-11-14 17:33:25,109 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local302270355_0002_m_000000_0 decomp: 74 len: 78 to MEMORY\n",
            "2025-11-14 17:33:25,111 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 74 bytes from map-output for attempt_local302270355_0002_m_000000_0\n",
            "2025-11-14 17:33:25,113 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 74, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->74\n",
            "2025-11-14 17:33:25,116 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
            "2025-11-14 17:33:25,117 [pool-5-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
            "2025-11-14 17:33:25,117 [pool-5-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
            "2025-11-14 17:33:25,124 [pool-5-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
            "2025-11-14 17:33:25,125 [pool-5-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 61 bytes\n",
            "2025-11-14 17:33:25,126 [pool-5-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 74 bytes to disk to satisfy reduce memory limit\n",
            "2025-11-14 17:33:25,126 [pool-5-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 78 bytes from disk\n",
            "2025-11-14 17:33:25,126 [pool-5-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
            "2025-11-14 17:33:25,127 [pool-5-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
            "2025-11-14 17:33:25,127 [pool-5-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 61 bytes\n",
            "2025-11-14 17:33:25,127 [pool-5-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
            "2025-11-14 17:33:25,134 [pool-5-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
            "2025-11-14 17:33:25,146 [pool-5-thread-1] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
            "2025-11-14 17:33:25,151 [pool-5-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (G1 Old Gen) of size 1048576000 to monitor. collectionUsageThreshold = 734003200, usageThreshold = 734003200\n",
            "2025-11-14 17:33:25,152 [pool-5-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
            "2025-11-14 17:33:25,158 [pool-5-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: sorted[14,9] C:  R: \n",
            "2025-11-14 17:33:25,165 [pool-5-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local302270355_0002_r_000000_0 is done. And is in the process of committing\n",
            "2025-11-14 17:33:25,171 [pool-5-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
            "2025-11-14 17:33:25,171 [pool-5-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local302270355_0002_r_000000_0 is allowed to commit now\n",
            "2025-11-14 17:33:25,176 [pool-5-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local302270355_0002_r_000000_0' to file:/tmp/temp-669726848/tmp2065602905/_temporary/0/task_local302270355_0002_r_000000\n",
            "2025-11-14 17:33:25,177 [pool-5-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
            "2025-11-14 17:33:25,177 [pool-5-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local302270355_0002_r_000000_0' done.\n",
            "2025-11-14 17:33:25,177 [pool-5-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local302270355_0002_r_000000_0\n",
            "2025-11-14 17:33:25,177 [Thread-44] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
            "2025-11-14 17:33:25,306 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 66% complete\n",
            "2025-11-14 17:33:25,310 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
            "2025-11-14 17:33:25,313 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
            "2025-11-14 17:33:25,315 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
            "2025-11-14 17:33:25,329 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
            "2025-11-14 17:33:25,331 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
            "2025-11-14 17:33:25,332 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
            "2025-11-14 17:33:25,332 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
            "2025-11-14 17:33:25,336 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
            "2025-11-14 17:33:25,360 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
            "2025-11-14 17:33:25,365 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
            "2025-11-14 17:33:25,378 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
            "2025-11-14 17:33:25,388 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1\n",
            "2025-11-14 17:33:25,388 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
            "2025-11-14 17:33:25,388 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
            "2025-11-14 17:33:25,415 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
            "2025-11-14 17:33:25,458 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local2073701640_0003\n",
            "2025-11-14 17:33:25,599 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
            "2025-11-14 17:33:25,599 [Thread-73] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
            "2025-11-14 17:33:25,608 [Thread-73] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
            "2025-11-14 17:33:25,608 [Thread-73] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
            "2025-11-14 17:33:25,608 [Thread-73] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
            "2025-11-14 17:33:25,609 [Thread-73] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
            "2025-11-14 17:33:25,609 [Thread-73] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
            "2025-11-14 17:33:25,616 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local2073701640_0003_m_000000_0\n",
            "2025-11-14 17:33:25,617 [Thread-73] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
            "2025-11-14 17:33:25,626 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
            "2025-11-14 17:33:25,627 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
            "2025-11-14 17:33:25,630 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
            "Total Length = 80\n",
            "Input split[0]:\n",
            "   Length = 80\n",
            "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
            "   Locations:\n",
            "\n",
            "-----------------------\n",
            "\n",
            "2025-11-14 17:33:25,633 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/tmp/temp-669726848/tmp-946096885/part-m-00000:0+80\n",
            "2025-11-14 17:33:25,671 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2025-11-14 17:33:25,671 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
            "2025-11-14 17:33:25,671 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
            "2025-11-14 17:33:25,671 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
            "2025-11-14 17:33:25,671 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
            "2025-11-14 17:33:25,673 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2025-11-14 17:33:25,678 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (G1 Old Gen) of size 1048576000 to monitor. collectionUsageThreshold = 734003200, usageThreshold = 734003200\n",
            "2025-11-14 17:33:25,681 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
            "2025-11-14 17:33:25,683 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: sorted[14,9] C:  R: \n",
            "2025-11-14 17:33:25,684 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
            "2025-11-14 17:33:25,684 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
            "2025-11-14 17:33:25,684 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
            "2025-11-14 17:33:25,684 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 92; bufvoid = 104857600\n",
            "2025-11-14 17:33:25,684 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214384(104857536); length = 13/6553600\n",
            "2025-11-14 17:33:25,686 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
            "2025-11-14 17:33:25,688 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local2073701640_0003_m_000000_0 is done. And is in the process of committing\n",
            "2025-11-14 17:33:25,694 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
            "2025-11-14 17:33:25,695 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local2073701640_0003_m_000000_0' done.\n",
            "2025-11-14 17:33:25,695 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local2073701640_0003_m_000000_0\n",
            "2025-11-14 17:33:25,698 [Thread-73] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
            "2025-11-14 17:33:25,699 [Thread-73] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
            "2025-11-14 17:33:25,699 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local2073701640_0003_r_000000_0\n",
            "2025-11-14 17:33:25,734 [pool-8-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
            "2025-11-14 17:33:25,744 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
            "2025-11-14 17:33:25,745 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@58ed5978\n",
            "2025-11-14 17:33:25,750 [pool-8-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=734003200, maxSingleShuffleLimit=183500800, mergeThreshold=484442144, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
            "2025-11-14 17:33:25,754 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local2073701640_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
            "2025-11-14 17:33:25,757 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local2073701640_0003_m_000000_0 decomp: 102 len: 106 to MEMORY\n",
            "2025-11-14 17:33:25,757 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 102 bytes from map-output for attempt_local2073701640_0003_m_000000_0\n",
            "2025-11-14 17:33:25,758 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 102, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->102\n",
            "2025-11-14 17:33:25,758 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
            "2025-11-14 17:33:25,760 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
            "2025-11-14 17:33:25,760 [pool-8-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
            "2025-11-14 17:33:25,763 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
            "2025-11-14 17:33:25,763 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 94 bytes\n",
            "2025-11-14 17:33:25,766 [pool-8-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 102 bytes to disk to satisfy reduce memory limit\n",
            "2025-11-14 17:33:25,766 [pool-8-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 106 bytes from disk\n",
            "2025-11-14 17:33:25,766 [pool-8-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
            "2025-11-14 17:33:25,766 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
            "2025-11-14 17:33:25,766 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 94 bytes\n",
            "2025-11-14 17:33:25,767 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
            "2025-11-14 17:33:25,772 [pool-8-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
            "2025-11-14 17:33:25,784 [pool-8-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (G1 Old Gen) of size 1048576000 to monitor. collectionUsageThreshold = 734003200, usageThreshold = 734003200\n",
            "2025-11-14 17:33:25,784 [pool-8-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
            "2025-11-14 17:33:25,787 [pool-8-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: sorted[14,9] C:  R: \n",
            "2025-11-14 17:33:25,790 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local2073701640_0003_r_000000_0 is done. And is in the process of committing\n",
            "2025-11-14 17:33:25,794 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
            "2025-11-14 17:33:25,794 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local2073701640_0003_r_000000_0 is allowed to commit now\n",
            "2025-11-14 17:33:25,798 [pool-8-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local2073701640_0003_r_000000_0' to file:/tmp/temp-669726848/tmp-401115398/_temporary/0/task_local2073701640_0003_r_000000\n",
            "2025-11-14 17:33:25,799 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
            "2025-11-14 17:33:25,799 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local2073701640_0003_r_000000_0' done.\n",
            "2025-11-14 17:33:25,799 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local2073701640_0003_r_000000_0\n",
            "2025-11-14 17:33:25,799 [Thread-73] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
            "2025-11-14 17:33:25,864 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local2073701640_0003\n",
            "2025-11-14 17:33:25,864 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases sorted\n",
            "2025-11-14 17:33:25,864 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: sorted[14,9] C:  R: \n",
            "2025-11-14 17:33:25,867 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_local2073701640_0003]\n",
            "2025-11-14 17:33:26,006 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
            "2025-11-14 17:33:26,008 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
            "2025-11-14 17:33:26,011 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
            "2025-11-14 17:33:26,018 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 100% complete\n",
            "2025-11-14 17:33:26,025 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats - Script Statistics: \n",
            "\n",
            "HadoopVersion\tPigVersion\tUserId\tStartedAt\tFinishedAt\tFeatures\n",
            "2.7.3\t0.17.0\troot\t2025-11-14 17:33:21\t2025-11-14 17:33:26\tORDER_BY,FILTER\n",
            "\n",
            "Success!\n",
            "\n",
            "Job Stats (time in seconds):\n",
            "JobId\tMaps\tReduces\tMaxMapTime\tMinMapTime\tAvgMapTime\tMedianMapTime\tMaxReduceTime\tMinReduceTime\tAvgReduceTime\tMedianReducetime\tAlias\tFeature\tOutputs\n",
            "job_local1292723063_0001\t1\t0\tn/a\tn/a\tn/a\tn/a\t0\t0\t0\t0\tgood_students,projected,students\tMAP_ONLY\t\n",
            "job_local2073701640_0003\t1\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tsorted\tORDER_BY\tfile:/tmp/temp-669726848/tmp-401115398,\n",
            "job_local302270355_0002\t1\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tsorted\tSAMPLER\t\n",
            "\n",
            "Input(s):\n",
            "Successfully read 5 records from: \"file:///content/students.csv\"\n",
            "\n",
            "Output(s):\n",
            "Successfully stored 4 records in: \"file:/tmp/temp-669726848/tmp-401115398\"\n",
            "\n",
            "Counters:\n",
            "Total records written : 4\n",
            "Total bytes written : 0\n",
            "Spillable Memory Manager spill count : 0\n",
            "Total bags proactively spilled: 0\n",
            "Total records proactively spilled: 0\n",
            "\n",
            "Job DAG:\n",
            "job_local1292723063_0001\t->\tjob_local302270355_0002,\n",
            "job_local302270355_0002\t->\tjob_local2073701640_0003,\n",
            "job_local2073701640_0003\n",
            "\n",
            "\n",
            "2025-11-14 17:33:26,029 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
            "2025-11-14 17:33:26,033 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
            "2025-11-14 17:33:26,035 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
            "2025-11-14 17:33:26,044 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
            "2025-11-14 17:33:26,046 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
            "2025-11-14 17:33:26,047 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
            "2025-11-14 17:33:26,055 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
            "2025-11-14 17:33:26,058 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
            "2025-11-14 17:33:26,061 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
            "2025-11-14 17:33:26,068 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Success!\n",
            "2025-11-14 17:33:26,074 [main] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
            "2025-11-14 17:33:26,085 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1\n",
            "2025-11-14 17:33:26,085 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
            "(Manish,IT,90)\n",
            "(Reena,CSE,85)\n",
            "(James,CSE,72)\n",
            "(Kiran,ECE,67)\n",
            "2025-11-14 17:33:26,122 [main] INFO  org.apache.pig.tools.pigstats.ScriptState - Pig features used in the script: GROUP_BY,FILTER\n",
            "2025-11-14 17:33:26,145 [main] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
            "2025-11-14 17:33:26,145 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}\n",
            "2025-11-14 17:33:26,148 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor - Columns pruned for students: $0\n",
            "2025-11-14 17:33:26,152 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler - File concatenation threshold: 100 optimistic? false\n",
            "2025-11-14 17:33:26,155 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - MR plan size before optimization: 1\n",
            "2025-11-14 17:33:26,155 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - MR plan size after optimization: 1\n",
            "2025-11-14 17:33:26,172 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
            "2025-11-14 17:33:26,174 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
            "2025-11-14 17:33:26,174 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
            "2025-11-14 17:33:26,175 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
            "2025-11-14 17:33:26,175 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Using reducer estimator: org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator\n",
            "2025-11-14 17:33:26,176 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator - BytesPerReducer=1000000000 maxReducers=999 totalInputFileSize=74\n",
            "2025-11-14 17:33:26,176 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
            "2025-11-14 17:33:26,178 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
            "2025-11-14 17:33:26,179 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Key [pig.schematuple] is false, will not generate code.\n",
            "2025-11-14 17:33:26,179 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Starting process to move generated code to distributed cacche\n",
            "2025-11-14 17:33:26,179 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Distributed cache not supported or needed in local mode. Setting key [pig.schematuple.local.dir] with code temp directory: /tmp/1763141606178-0\n",
            "2025-11-14 17:33:26,191 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
            "2025-11-14 17:33:26,195 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
            "2025-11-14 17:33:26,208 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
            "2025-11-14 17:33:26,211 [JobControl] INFO  org.apache.pig.builtin.PigStorage - Using PigTextInputFormat\n",
            "2025-11-14 17:33:26,212 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1\n",
            "2025-11-14 17:33:26,212 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
            "2025-11-14 17:33:26,212 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
            "2025-11-14 17:33:26,244 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
            "2025-11-14 17:33:26,278 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1993463856_0004\n",
            "2025-11-14 17:33:26,413 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
            "2025-11-14 17:33:26,414 [Thread-102] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
            "2025-11-14 17:33:26,421 [Thread-102] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
            "2025-11-14 17:33:26,422 [Thread-102] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
            "2025-11-14 17:33:26,422 [Thread-102] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
            "2025-11-14 17:33:26,422 [Thread-102] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
            "2025-11-14 17:33:26,423 [Thread-102] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
            "2025-11-14 17:33:26,431 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1993463856_0004_m_000000_0\n",
            "2025-11-14 17:33:26,431 [Thread-102] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
            "2025-11-14 17:33:26,440 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
            "2025-11-14 17:33:26,440 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
            "2025-11-14 17:33:26,442 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
            "Total Length = 74\n",
            "Input split[0]:\n",
            "   Length = 74\n",
            "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
            "   Locations:\n",
            "\n",
            "-----------------------\n",
            "\n",
            "2025-11-14 17:33:26,446 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.builtin.PigStorage - Using PigTextInputFormat\n",
            "2025-11-14 17:33:26,446 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/content/students.csv:0+74\n",
            "2025-11-14 17:33:26,509 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2025-11-14 17:33:26,510 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
            "2025-11-14 17:33:26,510 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
            "2025-11-14 17:33:26,510 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
            "2025-11-14 17:33:26,510 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
            "2025-11-14 17:33:26,512 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2025-11-14 17:33:26,517 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (G1 Old Gen) of size 1048576000 to monitor. collectionUsageThreshold = 734003200, usageThreshold = 734003200\n",
            "2025-11-14 17:33:26,519 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.data.SchemaTupleBackend - Key [pig.schematuple] was not set... will not generate code.\n",
            "2025-11-14 17:33:26,528 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: students[2,11],students[-1,-1],good_students[8,16],projected[10,12],grouped[12,10] C:  R: \n",
            "2025-11-14 17:33:26,533 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
            "2025-11-14 17:33:26,533 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
            "2025-11-14 17:33:26,534 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
            "2025-11-14 17:33:26,534 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 76; bufvoid = 104857600\n",
            "2025-11-14 17:33:26,534 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214384(104857536); length = 13/6553600\n",
            "2025-11-14 17:33:26,538 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
            "2025-11-14 17:33:26,541 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1993463856_0004_m_000000_0 is done. And is in the process of committing\n",
            "2025-11-14 17:33:26,560 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
            "2025-11-14 17:33:26,560 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1993463856_0004_m_000000_0' done.\n",
            "2025-11-14 17:33:26,560 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1993463856_0004_m_000000_0\n",
            "2025-11-14 17:33:26,560 [Thread-102] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
            "2025-11-14 17:33:26,561 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1993463856_0004_r_000000_0\n",
            "2025-11-14 17:33:26,561 [Thread-102] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
            "2025-11-14 17:33:26,581 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
            "2025-11-14 17:33:26,585 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
            "2025-11-14 17:33:26,585 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@c70413f\n",
            "2025-11-14 17:33:26,586 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=734003200, maxSingleShuffleLimit=183500800, mergeThreshold=484442144, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
            "2025-11-14 17:33:26,587 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1993463856_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
            "2025-11-14 17:33:26,590 [localfetcher#3] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#3 about to shuffle output of map attempt_local1993463856_0004_m_000000_0 decomp: 86 len: 90 to MEMORY\n",
            "2025-11-14 17:33:26,591 [localfetcher#3] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 86 bytes from map-output for attempt_local1993463856_0004_m_000000_0\n",
            "2025-11-14 17:33:26,591 [localfetcher#3] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 86, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->86\n",
            "2025-11-14 17:33:26,591 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
            "2025-11-14 17:33:26,592 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
            "2025-11-14 17:33:26,592 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
            "2025-11-14 17:33:26,594 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
            "2025-11-14 17:33:26,594 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 79 bytes\n",
            "2025-11-14 17:33:26,595 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 86 bytes to disk to satisfy reduce memory limit\n",
            "2025-11-14 17:33:26,595 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 90 bytes from disk\n",
            "2025-11-14 17:33:26,595 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
            "2025-11-14 17:33:26,595 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
            "2025-11-14 17:33:26,596 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 79 bytes\n",
            "2025-11-14 17:33:26,596 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
            "2025-11-14 17:33:26,602 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
            "2025-11-14 17:33:26,612 [pool-11-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (G1 Old Gen) of size 1048576000 to monitor. collectionUsageThreshold = 734003200, usageThreshold = 734003200\n",
            "2025-11-14 17:33:26,613 [pool-11-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
            "2025-11-14 17:33:26,614 [pool-11-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: students[2,11],students[-1,-1],good_students[8,16],projected[10,12],grouped[12,10] C:  R: \n",
            "2025-11-14 17:33:26,616 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1993463856_0004_r_000000_0 is done. And is in the process of committing\n",
            "2025-11-14 17:33:26,622 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
            "2025-11-14 17:33:26,624 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1993463856_0004_r_000000_0 is allowed to commit now\n",
            "2025-11-14 17:33:26,628 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1993463856_0004_r_000000_0' to file:/tmp/temp-669726848/tmp318119615/_temporary/0/task_local1993463856_0004_r_000000\n",
            "2025-11-14 17:33:26,628 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
            "2025-11-14 17:33:26,630 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1993463856_0004_r_000000_0' done.\n",
            "2025-11-14 17:33:26,630 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1993463856_0004_r_000000_0\n",
            "2025-11-14 17:33:26,630 [Thread-102] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
            "2025-11-14 17:33:26,694 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local1993463856_0004\n",
            "2025-11-14 17:33:26,694 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases good_students,grouped,projected,students\n",
            "2025-11-14 17:33:26,694 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: students[2,11],students[-1,-1],good_students[8,16],projected[10,12],grouped[12,10] C:  R: \n",
            "2025-11-14 17:33:26,696 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_local1993463856_0004]\n",
            "2025-11-14 17:33:26,819 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
            "2025-11-14 17:33:26,822 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
            "2025-11-14 17:33:26,824 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
            "2025-11-14 17:33:26,829 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 100% complete\n",
            "2025-11-14 17:33:26,829 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats - Script Statistics: \n",
            "\n",
            "HadoopVersion\tPigVersion\tUserId\tStartedAt\tFinishedAt\tFeatures\n",
            "2.7.3\t0.17.0\troot\t2025-11-14 17:33:26\t2025-11-14 17:33:26\tGROUP_BY,FILTER\n",
            "\n",
            "Success!\n",
            "\n",
            "Job Stats (time in seconds):\n",
            "JobId\tMaps\tReduces\tMaxMapTime\tMinMapTime\tAvgMapTime\tMedianMapTime\tMaxReduceTime\tMinReduceTime\tAvgReduceTime\tMedianReducetime\tAlias\tFeature\tOutputs\n",
            "job_local1993463856_0004\t1\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tgood_students,grouped,projected,students\tGROUP_BY\tfile:/tmp/temp-669726848/tmp318119615,\n",
            "\n",
            "Input(s):\n",
            "Successfully read 5 records from: \"file:///content/students.csv\"\n",
            "\n",
            "Output(s):\n",
            "Successfully stored 3 records in: \"file:/tmp/temp-669726848/tmp318119615\"\n",
            "\n",
            "Counters:\n",
            "Total records written : 3\n",
            "Total bytes written : 0\n",
            "Spillable Memory Manager spill count : 0\n",
            "Total bags proactively spilled: 0\n",
            "Total records proactively spilled: 0\n",
            "\n",
            "Job DAG:\n",
            "job_local1993463856_0004\n",
            "\n",
            "\n",
            "2025-11-14 17:33:26,833 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
            "2025-11-14 17:33:26,834 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
            "2025-11-14 17:33:26,839 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
            "2025-11-14 17:33:26,842 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Success!\n",
            "2025-11-14 17:33:26,846 [main] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
            "2025-11-14 17:33:26,858 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1\n",
            "2025-11-14 17:33:26,858 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
            "(IT,{(Manish,IT,90)})\n",
            "(CSE,{(James,CSE,72),(Reena,CSE,85)})\n",
            "(ECE,{(Kiran,ECE,67)})\n",
            "2025-11-14 17:33:26,903 [main] INFO  org.apache.pig.tools.pigstats.ScriptState - Pig features used in the script: HASH_JOIN,FILTER\n",
            "2025-11-14 17:33:26,930 [main] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
            "2025-11-14 17:33:26,931 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}\n",
            "2025-11-14 17:33:26,936 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor - Columns pruned for students: $0\n",
            "2025-11-14 17:33:26,941 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler - File concatenation threshold: 100 optimistic? false\n",
            "2025-11-14 17:33:26,947 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer - Rewrite: POPackage->POForEach to POPackage(JoinPackager)\n",
            "2025-11-14 17:33:26,947 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - MR plan size before optimization: 1\n",
            "2025-11-14 17:33:26,947 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - MR plan size after optimization: 1\n",
            "2025-11-14 17:33:26,970 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
            "2025-11-14 17:33:26,973 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
            "2025-11-14 17:33:26,973 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
            "2025-11-14 17:33:26,974 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
            "2025-11-14 17:33:26,974 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Using reducer estimator: org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator\n",
            "2025-11-14 17:33:26,975 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator - BytesPerReducer=1000000000 maxReducers=999 totalInputFileSize=112\n",
            "2025-11-14 17:33:26,975 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
            "2025-11-14 17:33:26,977 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
            "2025-11-14 17:33:26,978 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Key [pig.schematuple] is false, will not generate code.\n",
            "2025-11-14 17:33:26,978 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Starting process to move generated code to distributed cacche\n",
            "2025-11-14 17:33:26,978 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Distributed cache not supported or needed in local mode. Setting key [pig.schematuple.local.dir] with code temp directory: /tmp/1763141606978-0\n",
            "2025-11-14 17:33:26,996 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
            "2025-11-14 17:33:26,998 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
            "2025-11-14 17:33:27,012 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
            "2025-11-14 17:33:27,015 [JobControl] INFO  org.apache.pig.builtin.PigStorage - Using PigTextInputFormat\n",
            "2025-11-14 17:33:27,015 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1\n",
            "2025-11-14 17:33:27,016 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
            "2025-11-14 17:33:27,016 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
            "2025-11-14 17:33:27,017 [JobControl] INFO  org.apache.pig.builtin.PigStorage - Using PigTextInputFormat\n",
            "2025-11-14 17:33:27,018 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1\n",
            "2025-11-14 17:33:27,018 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
            "2025-11-14 17:33:27,018 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
            "2025-11-14 17:33:27,048 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2\n",
            "2025-11-14 17:33:27,084 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local281241714_0005\n",
            "2025-11-14 17:33:27,171 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
            "2025-11-14 17:33:27,171 [Thread-131] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
            "2025-11-14 17:33:27,178 [Thread-131] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
            "2025-11-14 17:33:27,179 [Thread-131] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
            "2025-11-14 17:33:27,179 [Thread-131] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
            "2025-11-14 17:33:27,179 [Thread-131] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
            "2025-11-14 17:33:27,180 [Thread-131] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
            "2025-11-14 17:33:27,185 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local281241714_0005_m_000000_0\n",
            "2025-11-14 17:33:27,185 [Thread-131] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
            "2025-11-14 17:33:27,195 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
            "2025-11-14 17:33:27,195 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
            "2025-11-14 17:33:27,197 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
            "Total Length = 74\n",
            "Input split[0]:\n",
            "   Length = 74\n",
            "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
            "   Locations:\n",
            "\n",
            "-----------------------\n",
            "\n",
            "2025-11-14 17:33:27,201 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.builtin.PigStorage - Using PigTextInputFormat\n",
            "2025-11-14 17:33:27,201 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/content/students.csv:0+74\n",
            "2025-11-14 17:33:27,242 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2025-11-14 17:33:27,243 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
            "2025-11-14 17:33:27,243 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
            "2025-11-14 17:33:27,243 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
            "2025-11-14 17:33:27,243 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
            "2025-11-14 17:33:27,246 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2025-11-14 17:33:27,257 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (G1 Old Gen) of size 1048576000 to monitor. collectionUsageThreshold = 734003200, usageThreshold = 734003200\n",
            "2025-11-14 17:33:27,258 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.data.SchemaTupleBackend - Key [pig.schematuple] was not set... will not generate code.\n",
            "2025-11-14 17:33:27,288 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: students[2,11],students[-1,-1],good_students[8,16],projected[10,12],joined[16,9],departments[5,14],departments[-1,-1],joined[16,9] C:  R: \n",
            "2025-11-14 17:33:27,291 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
            "2025-11-14 17:33:27,291 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
            "2025-11-14 17:33:27,291 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
            "2025-11-14 17:33:27,291 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 76; bufvoid = 104857600\n",
            "2025-11-14 17:33:27,291 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214384(104857536); length = 13/6553600\n",
            "2025-11-14 17:33:27,292 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
            "2025-11-14 17:33:27,294 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local281241714_0005_m_000000_0 is done. And is in the process of committing\n",
            "2025-11-14 17:33:27,295 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
            "2025-11-14 17:33:27,295 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local281241714_0005_m_000000_0' done.\n",
            "2025-11-14 17:33:27,295 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local281241714_0005_m_000000_0\n",
            "2025-11-14 17:33:27,295 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local281241714_0005_m_000001_0\n",
            "2025-11-14 17:33:27,301 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
            "2025-11-14 17:33:27,301 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
            "2025-11-14 17:33:27,302 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
            "Total Length = 38\n",
            "Input split[0]:\n",
            "   Length = 38\n",
            "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
            "   Locations:\n",
            "\n",
            "-----------------------\n",
            "\n",
            "2025-11-14 17:33:27,305 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.builtin.PigStorage - Using PigTextInputFormat\n",
            "2025-11-14 17:33:27,305 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/content/departments.csv:0+38\n",
            "2025-11-14 17:33:27,389 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2025-11-14 17:33:27,390 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
            "2025-11-14 17:33:27,390 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
            "2025-11-14 17:33:27,390 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
            "2025-11-14 17:33:27,390 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
            "2025-11-14 17:33:27,392 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2025-11-14 17:33:27,397 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (G1 Old Gen) of size 1048576000 to monitor. collectionUsageThreshold = 734003200, usageThreshold = 734003200\n",
            "2025-11-14 17:33:27,400 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
            "2025-11-14 17:33:27,413 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: students[2,11],students[-1,-1],good_students[8,16],projected[10,12],joined[16,9],departments[5,14],departments[-1,-1],joined[16,9] C:  R: \n",
            "2025-11-14 17:33:27,417 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
            "2025-11-14 17:33:27,418 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
            "2025-11-14 17:33:27,418 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
            "2025-11-14 17:33:27,418 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 59; bufvoid = 104857600\n",
            "2025-11-14 17:33:27,418 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214388(104857552); length = 9/6553600\n",
            "2025-11-14 17:33:27,420 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
            "2025-11-14 17:33:27,422 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local281241714_0005_m_000001_0 is done. And is in the process of committing\n",
            "2025-11-14 17:33:27,425 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
            "2025-11-14 17:33:27,426 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local281241714_0005_m_000001_0' done.\n",
            "2025-11-14 17:33:27,426 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local281241714_0005_m_000001_0\n",
            "2025-11-14 17:33:27,426 [Thread-131] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
            "2025-11-14 17:33:27,427 [pool-14-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local281241714_0005_r_000000_0\n",
            "2025-11-14 17:33:27,428 [Thread-131] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
            "2025-11-14 17:33:27,440 [pool-14-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
            "2025-11-14 17:33:27,444 [pool-14-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
            "2025-11-14 17:33:27,444 [pool-14-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@223f1347\n",
            "2025-11-14 17:33:27,445 [pool-14-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=734003200, maxSingleShuffleLimit=183500800, mergeThreshold=484442144, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
            "2025-11-14 17:33:27,448 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local281241714_0005_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
            "2025-11-14 17:33:27,449 [localfetcher#4] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#4 about to shuffle output of map attempt_local281241714_0005_m_000001_0 decomp: 67 len: 71 to MEMORY\n",
            "2025-11-14 17:33:27,450 [localfetcher#4] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 67 bytes from map-output for attempt_local281241714_0005_m_000001_0\n",
            "2025-11-14 17:33:27,450 [localfetcher#4] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 67, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->67\n",
            "2025-11-14 17:33:27,451 [localfetcher#4] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#4 about to shuffle output of map attempt_local281241714_0005_m_000000_0 decomp: 86 len: 90 to MEMORY\n",
            "2025-11-14 17:33:27,451 [localfetcher#4] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 86 bytes from map-output for attempt_local281241714_0005_m_000000_0\n",
            "2025-11-14 17:33:27,451 [localfetcher#4] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 86, inMemoryMapOutputs.size() -> 2, commitMemory -> 67, usedMemory ->153\n",
            "2025-11-14 17:33:27,452 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
            "2025-11-14 17:33:27,453 [pool-14-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.\n",
            "2025-11-14 17:33:27,453 [pool-14-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs\n",
            "2025-11-14 17:33:27,454 [pool-14-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 2 sorted segments\n",
            "2025-11-14 17:33:27,454 [pool-14-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 2 segments left of total size: 139 bytes\n",
            "2025-11-14 17:33:27,459 [pool-14-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 2 segments, 153 bytes to disk to satisfy reduce memory limit\n",
            "2025-11-14 17:33:27,459 [pool-14-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 155 bytes from disk\n",
            "2025-11-14 17:33:27,459 [pool-14-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
            "2025-11-14 17:33:27,459 [pool-14-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
            "2025-11-14 17:33:27,459 [pool-14-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 144 bytes\n",
            "2025-11-14 17:33:27,460 [pool-14-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.\n",
            "2025-11-14 17:33:27,465 [pool-14-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
            "2025-11-14 17:33:27,472 [pool-14-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (G1 Old Gen) of size 1048576000 to monitor. collectionUsageThreshold = 734003200, usageThreshold = 734003200\n",
            "2025-11-14 17:33:27,472 [pool-14-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
            "2025-11-14 17:33:27,474 [pool-14-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: students[2,11],students[-1,-1],good_students[8,16],projected[10,12],joined[16,9],departments[5,14],departments[-1,-1],joined[16,9] C:  R: \n",
            "2025-11-14 17:33:27,475 [pool-14-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local281241714_0005_r_000000_0 is done. And is in the process of committing\n",
            "2025-11-14 17:33:27,479 [pool-14-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.\n",
            "2025-11-14 17:33:27,479 [pool-14-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local281241714_0005_r_000000_0 is allowed to commit now\n",
            "2025-11-14 17:33:27,482 [pool-14-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local281241714_0005_r_000000_0' to file:/tmp/temp-669726848/tmp-1553589787/_temporary/0/task_local281241714_0005_r_000000\n",
            "2025-11-14 17:33:27,483 [pool-14-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
            "2025-11-14 17:33:27,483 [pool-14-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local281241714_0005_r_000000_0' done.\n",
            "2025-11-14 17:33:27,483 [pool-14-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local281241714_0005_r_000000_0\n",
            "2025-11-14 17:33:27,485 [Thread-131] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
            "2025-11-14 17:33:27,497 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local281241714_0005\n",
            "2025-11-14 17:33:27,497 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases departments,good_students,joined,projected,students\n",
            "2025-11-14 17:33:27,497 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: students[2,11],students[-1,-1],good_students[8,16],projected[10,12],joined[16,9],departments[5,14],departments[-1,-1],joined[16,9] C:  R: \n",
            "2025-11-14 17:33:27,503 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_local281241714_0005]\n",
            "2025-11-14 17:33:27,695 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
            "2025-11-14 17:33:27,697 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
            "2025-11-14 17:33:27,698 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
            "2025-11-14 17:33:27,706 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 100% complete\n",
            "2025-11-14 17:33:27,707 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats - Script Statistics: \n",
            "\n",
            "HadoopVersion\tPigVersion\tUserId\tStartedAt\tFinishedAt\tFeatures\n",
            "2.7.3\t0.17.0\troot\t2025-11-14 17:33:26\t2025-11-14 17:33:27\tHASH_JOIN,FILTER\n",
            "\n",
            "Success!\n",
            "\n",
            "Job Stats (time in seconds):\n",
            "JobId\tMaps\tReduces\tMaxMapTime\tMinMapTime\tAvgMapTime\tMedianMapTime\tMaxReduceTime\tMinReduceTime\tAvgReduceTime\tMedianReducetime\tAlias\tFeature\tOutputs\n",
            "job_local281241714_0005\t2\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tdepartments,good_students,joined,projected,students\tHASH_JOIN\tfile:/tmp/temp-669726848/tmp-1553589787,\n",
            "\n",
            "Input(s):\n",
            "Successfully read 5 records from: \"file:///content/students.csv\"\n",
            "Successfully read 3 records from: \"file:///content/departments.csv\"\n",
            "\n",
            "Output(s):\n",
            "Successfully stored 4 records in: \"file:/tmp/temp-669726848/tmp-1553589787\"\n",
            "\n",
            "Counters:\n",
            "Total records written : 4\n",
            "Total bytes written : 0\n",
            "Spillable Memory Manager spill count : 0\n",
            "Total bags proactively spilled: 0\n",
            "Total records proactively spilled: 0\n",
            "\n",
            "Job DAG:\n",
            "job_local281241714_0005\n",
            "\n",
            "\n",
            "2025-11-14 17:33:27,711 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
            "2025-11-14 17:33:27,715 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
            "2025-11-14 17:33:27,716 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
            "2025-11-14 17:33:27,721 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Success!\n",
            "2025-11-14 17:33:27,725 [main] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
            "2025-11-14 17:33:27,733 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1\n",
            "2025-11-14 17:33:27,733 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
            "(Manish,IT,90,IT,Dr.Vaavar)\n",
            "(James,CSE,72,CSE,Dr.Rao)\n",
            "(Reena,CSE,85,CSE,Dr.Rao)\n",
            "(Kiran,ECE,67,ECE,Dr.Sharma)\n",
            "2025-11-14 17:33:27,763 [main] INFO  org.apache.pig.Main - Pig script completed in 8 seconds and 199 milliseconds (8199 ms)\n"
          ]
        }
      ]
    }
  ]
}